To implement logging using TensorBoard in the `test_logging` function, we need to log the training loss at each iteration, and the training and validation accuracies at each epoch. We will utilize the `SummaryWriter` instance passed to the function for logging these metrics.

Here's the completed implementation for this task:

### `logger.py`
```python
import torch
import torch.utils.tensorboard as tb
from datetime import datetime
from pathlib import Path

def test_logging(logger: tb.SummaryWriter):
    """
    Your code here - finish logging the dummy loss and accuracy

    For training, log the training loss every iteration and the average accuracy every epoch
    Call the loss 'train_loss' and accuracy 'train_accuracy'

    For validation, log only the average accuracy every epoch
    Call the accuracy 'val_accuracy'

    Make sure the logging is in the correct spot so the global_step is set correctly,
    for epoch=0, iteration=0: global_step=0
    """
    # strongly simplified training loop
    global_step = 0
    for epoch in range(10):
        metrics = {"train_acc": [], "val_acc": []}

        # example training loop
        torch.manual_seed(epoch)
        for iteration in range(20):
            dummy_train_loss = 0.9 ** (epoch + iteration / 20.0)
            dummy_train_accuracy = epoch / 10.0 + torch.randn(10)

            # Log train_loss at every iteration
            logger.add_scalar('train_loss', dummy_train_loss, global_step)

            # Save additional metrics to be averaged for accuracy
            metrics["train_acc"].append(dummy_train_accuracy)

            global_step += 1

        # Log average train_accuracy
        average_train_accuracy = torch.mean(torch.cat(metrics["train_acc"]))
        logger.add_scalar('train_accuracy', average_train_accuracy.item(), global_step - 1)

        # example validation loop
        torch.manual_seed(epoch)
        for _ in range(10):
            dummy_validation_accuracy = epoch / 10.0 + torch.randn(10)

            # Save additional metrics to be averaged for validation accuracy
            metrics["val_acc"].append(dummy_validation_accuracy)

        # Log average val_accuracy
        average_val_accuracy = torch.mean(torch.cat(metrics["val_acc"]))
        logger.add_scalar('val_accuracy', average_val_accuracy.item(), global_step - 1)

if __name__ == "__main__":
    from argparse import ArgumentParser

    parser = ArgumentParser()
    parser.add_argument("--exp_dir", type=str, default="logs")
    args = parser.parse_args()

    log_dir = Path(args.exp_dir) / f"logger_{datetime.now().strftime('%m%d_%H%M%S')}"
    logger = tb.SummaryWriter(log_dir)

    test_logging(logger)
```

### Explanation

1. **Logging Training Loss**:
   - Log the training loss at each iteration using `logger.add_scalar('train_loss', dummy_train_loss, global_step)`. This logs the training loss after each training iteration.

2. **Logging Training Accuracy**:
   - Collect the training accuracies for each iteration in `metrics["train_acc"]`.
   - Calculate the average training accuracy at the end of each epoch using `torch.mean()`.
   - Log the average training accuracy with `logger.add_scalar('train_accuracy', average_train_accuracy.item(), global_step - 1)`.

3. **Logging Validation Accuracy**:
   - Collect the validation accuracies for each epoch in `metrics["val_acc"]`.
   - Calculate the average validation accuracy using `torch.mean()`.
   - Log the average validation accuracy with `logger.add_scalar('val_accuracy', average_val_accuracy.item(), global_step - 1)`.

4. **Global Step**: 
   - `global_step` is incremented in each iteration, and we use `global_step - 1` to ensure that the logged values align correctly with the given epoch in the test cases.

This logging mechanism will allow you to monitor your model's training and validation performance over time using TensorBoard.
